
import React from 'react';
import { MethodologyStepItem } from '../types';

export const PENETRATION_TESTING_STEPS: MethodologyStepItem[] = [
  {
    id: 'subdomain-enumeration',
    title: 'Subdomain Enumeration & Reconnaissance',
    icon: 'fas fa-sitemap',
    description: 'The foundational phase of any penetration test is to comprehensively map the target\'s digital footprint. Subdomain enumeration is key to discovering all associated domains and subdomains, which often host various applications and services, potentially expanding the attack surface significantly. This phase involves both passive and active techniques.',
    interactiveElement: {
      type: 'text-input',
      label: 'Target Root Domain:',
      initialValue: 'example.com',
      placeholder: 'Enter target root domain (e.g., example.com)',
    },
    explanation: 'A thorough subdomain enumeration can uncover forgotten applications, development environments, or internal services mistakenly exposed to the internet. Each discovered subdomain should be further investigated.',
    tips: [
      "Always combine results from multiple tools and techniques for the most comprehensive list.",
      "Verify resolved IPs for subdomains; some might point to the same host, while others might be on different infrastructure.",
      "Be aware of wildcard DNS; it can generate many false positives for active brute-forcing techniques. Check for it first.",
      "Archive your results; subdomain lists can change over time."
    ],
    subSteps: [
      {
        id: 'subdomain-passive',
        title: 'Passive Enumeration Techniques',
        description: 'Gather subdomains using publicly available information without directly probing the target\'s servers. This is stealthy and often yields a good initial list.',
        commands: [
          { language: 'bash', code: (params: any) => `subfinder -d ${params.targetDomain || 'example.com'} -silent -o subfinder_passive.txt`, showCopyButton: true },
          { language: 'bash', code: (params: any) => `assetfinder --subs-only ${params.targetDomain || 'example.com'} > assetfinder_passive.txt`, showCopyButton: true },
          { language: 'bash', code: (params: any) => `amass enum -passive -d ${params.targetDomain || 'example.com'} -o amass_passive.txt`, showCopyButton: true },
        ],
        explanation: `Tools like <strong>Subfinder</strong>, <strong>Assetfinder</strong>, and <strong>Amass (in passive mode)</strong> query various sources:
            <ul class="list-disc list-inside ml-4 my-2 text-sm">
              <li>Search Engines (Google, Bing, Yahoo, etc. using dorks)</li>
              <li>Public DNS datasets (e.g., Rapid7 SonarDNS, DNSDB - some require API keys)</li>
              <li>Certificate Transparency Logs (crt.sh, censys.io)</li>
              <li>Online repositories and archives (Wayback Machine, GitHub, GitLab)</li>
              <li>Threat intelligence platforms</li>
            </ul>
            These tools aggregate results, providing a broad overview of known subdomains.`,
        tips: ["Use multiple passive tools as they often use different data sources.", "Regularly update your tools for new sources and bug fixes."]
      },
      {
        id: 'subdomain-crtsh',
        title: 'Certificate Transparency Logs (crt.sh)',
        description: 'Query crt.sh directly for certificates issued to a domain, which often reveals subdomains.',
        commands: [
           { language: 'bash', code: (params: any) => `curl -s "https://crt.sh/?q=%.${params.targetDomain || 'example.com'}&output=json" | jq -r '.[].name_value' | sed 's/\\*\\.//g' | sort -u > crtsh_subdomains.txt`, showCopyButton: true },
        ],
        explanation: 'crt.sh aggregates certificate transparency logs. This command fetches JSON data, extracts common names and subject alternative names, removes wildcards, and sorts unique entries. This is a very effective passive technique.',
        tips: ["This method can reveal internal hostnames if they have publicly trusted certificates.", "Can be noisy with many wildcard certificate entries if not filtered properly."]
      },
      {
        id: 'subdomain-active-bruteforce',
        title: 'Active Brute-Forcing',
        description: 'Attempt to discover subdomains by prepending common words from a wordlist to the target domain and checking if they resolve in DNS.',
        commands: [
          { language: 'bash', code: (params: any) => `dnsrecon -d ${params.targetDomain || 'example.com'} -t brt -w /usr/share/wordlists/dnsmap.txt -j dnsrecon_brute.json`, showCopyButton: true },
          { language: 'bash', code: (params: any) => `gobuster dns -d ${params.targetDomain || 'example.com'} -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-5000.txt -o gobuster_dns.txt`, showCopyButton: true },
          { language: 'bash', code: (params: any) => `ffuf -w /usr/share/seclists/Discovery/DNS/subdomains-top1million-20000.txt -u http://FUZZ.${params.targetDomain || 'example.com'} -H "Host: FUZZ.${params.targetDomain || 'example.com'}" -fs <SIZE_OF_INVALID_PAGE> -o ffuf_dns.txt`, showCopyButton: true},
        ],
        explanation: `Tools like <strong>dnsrecon</strong>, <strong>gobuster (dns mode)</strong>, or <strong>ffuf</strong> are used with wordlists (e.g., from SecLists).
            <ul class="list-disc list-inside ml-4 my-2 text-sm">
              <li><strong>Wordlists:</strong> The quality of the wordlist is crucial. Common choices include SecLists&apos; subdomain lists.</li>
              <li><strong>Resolvers:</strong> Using reliable and fast DNS resolvers can speed up the process. Consider using a custom list of resolvers.</li>
              <li><strong>Wildcard Detection:</strong> These tools usually have mechanisms to detect wildcard DNS entries (e.g., <code>*.example.com</code> resolving to an IP) to avoid false positives.</li>
            </ul>`,
        tips: ["Brute-forcing can be noisy and time-consuming. Start with smaller, high-quality wordlists before moving to larger ones.", "Adjust thread counts based on your network and target responsiveness."]
      },
      {
        id: 'subdomain-permutations',
        title: 'Permutation Scanning',
        description: 'Generate variations of known subdomains to discover new ones. This is useful if you have an initial list of subdomains.',
        commands: [
          { language: 'bash', code: (params: any) => `# Assuming initial_subdomains.txt exists\ndnsgen initial_subdomains.txt -w wordlist_for_permutations.txt | massdns -r /path/to/resolvers.txt -t A -o S -w dnsgen_massdns_results.txt`, showCopyButton: true },
          { language: 'bash', code: (params: any) => `althosts initial_subdomains.txt ${params.targetDomain || 'example.com'} | xargs -P50 -I{} host {} | grep "has address"`, showCopyButton: true },
        ],
        explanation: `<strong>DNSGen</strong> generates permutations by adding words, numbers, or replacing parts of known subdomains. The output is then resolved using a fast resolver like <strong>MassDNS</strong>.
            <strong>AltHosts</strong> is another tool that creates permutations of subdomains and resolves them.`,
        tips: ["Permutation scanning can uncover patterns used by developers, like dev-, test-, stage- prefixed subdomains.", "Ensure your resolver list for MassDNS is reliable."]
      },
      {
        id: 'subdomain-vhost',
        title: 'Virtual Host (VHost) Enumeration',
        description: 'Sometimes, multiple websites are hosted on the same IP address, distinguished by the HTTP Host header. VHost enumeration tries to find these hidden hostnames.',
        commands: [
            { language: 'bash', code: (params: any) => `ffuf -w /path/to/vhost_wordlist.txt -u http://${params.targetIpOrHost || 'TARGET_IP'} -H "Host: FUZZ.${params.targetDomain || 'example.com'}" -fs <SIZE_OF_DEFAULT_PAGE_ON_IP> -o ffuf_vhosts.txt`, params: {targetIpOrHost: 'TARGET_IP_HERE'}, showCopyButton: true},
        ],
        explanation: 'This uses `ffuf` to send requests to a specific IP address while iterating through potential hostnames in the Host header. You need to identify the size of the default page served by the IP to filter out baseline responses.',
        tips: ["Find IPs associated with your target domain first. Then, use those IPs for VHost fuzzing.", "Good wordlists for VHost fuzzing can be found in SecLists (e.g., VirtualHostDiscovery)."]
      },
      {
        id: 'subdomain-validation-resolution',
        title: 'Validation and Resolution',
        description: 'After gathering potential subdomains from various sources, it\'s crucial to resolve them to IP addresses and check if they are live.',
        commands: [
          { language: 'bash', code: `# Combine all found subdomains into one file first, e.g., all_potential_subdomains.txt
cat *.txt | sort -u > all_potential_subdomains.txt`, showCopyButton: false },
          { language: 'bash', code: `massdns -r /path/to/resolvers.txt -t A -o S all_potential_subdomains.txt -w resolved_subdomains.txt`, showCopyButton: true },
          { language: 'bash', code: `cat resolved_subdomains.txt | awk '{print $1}' | sed 's/\\.$//' | sort -u > unique_resolved_hostnames.txt # Extract hostnames`, showCopyButton: true },
          { language: 'bash', code: `cat resolved_subdomains.txt | awk '{print $3}' | sort -u > unique_resolved_ips.txt # Extract IPs`, showCopyButton: true },
        ],
        explanation: '<strong>MassDNS</strong> is a very fast DNS resolver. The output typically contains the hostname, record type (A), and IP address. We then process this to get unique lists of resolved hostnames and IPs.',
        tips: ["A good list of public DNS resolvers can improve MassDNS performance and reliability.", "Some subdomains might resolve to internal IP addresses; note these down as they could be interesting for internal pivoting if external access is gained."]
      }
    ]
  },
  {
    id: 'port-scanning',
    title: 'Port Scanning with Nmap & Alternatives',
    icon: 'fas fa-network-wired',
    description: 'Once live hosts are identified, port scanning is performed to discover open TCP and UDP ports, and the services running on them. This is crucial for understanding the exposed services and potential entry points on each host.',
    interactiveElement: {
        type: 'tabs',
        label: 'Nmap Scanning Techniques & Flags',
        options: [
            { 
                id: 'nmap-scan-types', 
                name: 'Common Scan Types', 
                content: `
                    <ul class="list-disc list-inside text-sm">
                        <li><strong>TCP SYN Scan (<code>-sS</code>):</strong> Default for privileged users. Stealthy and fast. Completes half of the TCP handshake.</li>
                        <li><strong>TCP Connect Scan (<code>-sT</code>):</strong> Default for unprivileged users. Completes the full TCP handshake. More easily logged.</li>
                        <li><strong>UDP Scan (<code>-sU</code>):</strong> Scans for open UDP ports. Slower and more challenging than TCP scanning due to UDP's connectionless nature.</li>
                        <li><strong>FIN, Null, Xmas Scans (<code>-sF</code>, <code>-sN</code>, <code>-sX</code>):</strong> Stealthy scans that can bypass some stateless firewalls. Rely on specific RFC 793 behaviors.</li>
                    </ul>
                `
            },
            { 
                id: 'nmap-common-flags', 
                name: 'Essential Flags', 
                content: `
                    <ul class="list-disc list-inside text-sm">
                        <li><code>-p &lt;ports&gt;</code>: Specify ports (e.g., <code>-p21,22,80,443</code>, <code>-p-</code> for all 65535, <code>-p U:53,T:21-25</code> for specific UDP/TCP).</li>
                        <li><code>-sV</code>: Service/Version detection. Probes open ports to determine service and version info.</li>
                        <li><code>-O</code>: Enable OS detection. Attempts to identify the operating system of the target.</li>
                        <li><code>-A</code>: Aggressive scan. Enables OS detection, version detection, script scanning, and traceroute. Noisy.</li>
                        <li><code>-sC</code> or <code>--script default</code>: Run default Nmap Scripting Engine (NSE) scripts.</li>
                        <li><code>--script &lt;category|scriptname&gt;</code>: Run specific NSE scripts or categories (e.g., <code>vuln</code>, <code>discovery</code>).</li>
                        <li><code>-T&lt;0-5&gt;</code>: Set timing template (T0=paranoid, T5=insane). T4 is often a good balance.</li>
                        <li><code>-n</code>: No DNS resolution. <code>-R</code>: Resolve DNS for all targets.</li>
                        <li><code>-Pn</code>: Skip host discovery (ping scan). Treat all hosts as online. Useful if ICMP is blocked.</li>
                        <li><code>-iL &lt;inputfile&gt;</code>: Scan targets from a file.</li>
                        <li><code>-oN &lt;file&gt;</code>, <code>-oX &lt;file&gt;</code>, <code>-oG &lt;file&gt;</code>, <code>-oA &lt;basename&gt;</code>: Output formats (Normal, XML, Grepable, All).</li>
                        <li><code>--min-rate &lt;num&gt;</code> / <code>--max-rate &lt;num&gt;</code>: Control scan speed.</li>
                        <li><code>-v</code> / <code>-vv</code>: Increase verbosity.</li>
                        <li><code>--reason</code>: Display the reason a port is in a particular state.</li>
                    </ul>
                `
            }
        ],
    },
    explanation: 'Nmap is the de-facto standard for port scanning. Choosing the right scan type, timing, and flags is essential for accurate and efficient results.',
    tips: [
        "Always get proper authorization before scanning any target.",
        "Start with a quick scan of common ports, then do a full port scan on interesting hosts if time permits.",
        "XML output (<code>-oX</code>) is very useful for parsing results with other tools.",
        "Be mindful of network intrusion detection/prevention systems (NIDS/NIPS); overly aggressive scans can trigger alerts or get your IP blocked."
    ],
    subSteps: [
      {
        id: 'portscan-initial-tcp',
        title: 'Initial TCP Port Scan (Common Ports)',
        description: 'Perform a quick scan of the most common TCP ports to get an initial overview of services.',
        commands: [
          { language: 'bash', code: (params: any) => `nmap -iL unique_resolved_hostnames.txt -p T:21,22,23,25,53,80,110,111,135,139,143,443,445,993,995,1723,3306,3389,5900,8080,8443 -sS -sV --open -T4 -oA nmap_initial_tcp_common --min-rate=500`, showCopyButton: true },
        ],
        explanation: 'This Nmap command scans a list of hosts (<code>unique_resolved_hostnames.txt</code>) for a predefined list of common TCP ports. <code>-sS</code> (SYN scan), <code>-sV</code> (version detection), <code>--open</code> (only show open ports), <code>-T4</code> (aggressive timing), <code>-oA</code> (output all formats), <code>--min-rate=500</code> (scan speed).',
        tips: ["The <code>--open</code> flag is useful to reduce output noise, showing only actively listening services.", "Adjust <code>--min-rate</code> based on network conditions and target sensitivity."]
      },
      {
        id: 'portscan-full-tcp',
        title: 'Full TCP Port Scan (All 65535 Ports)',
        description: 'On selected interesting hosts, perform a full TCP port scan to discover any services running on non-standard ports.',
        commands: [
          { language: 'bash', code: (params: any) => `nmap ${params.targetHost || 'TARGET_IP_OR_HOSTNAME'} -p- -sS -sV -T4 -oA nmap_full_tcp_${params.targetHost || 'TARGET'} --min-rate=1000`, params: { targetHost: 'specific_target.example.com'}, showCopyButton: true },
        ],
        explanation: '<code>-p-</code> tells Nmap to scan all 65535 TCP ports. This can be time-consuming but is crucial for finding hidden services.',
        tips: ["This scan can be very noisy and take a long time. Run it on specific high-value targets identified from initial scans.", "Consider using <code>--max-retries 1</code> to speed up if you are confident in network reliability."]
      },
      {
        id: 'portscan-udp',
        title: 'UDP Port Scan (Common Ports)',
        description: 'Scan for common open UDP ports. UDP scanning is generally slower and less reliable than TCP scanning.',
        commands: [
          { language: 'bash', code: (params: any) => `nmap -iL unique_resolved_hostnames.txt -sU -p U:53,67,68,69,123,137,138,161,162,500,514,4500 --top-ports 20 -T4 -oA nmap_udp_common`, showCopyButton: true },
           { language: 'bash', code: (params: any) => `unicornscan -i eth0 -mU -Iv ${params.targetHost || 'TARGET_IP_OR_HOSTNAME'}:1-65535 # Alternative faster UDP scanner`, params: {targetHost: 'specific_target.example.com'}, showCopyButton: true}
        ],
        explanation: '<code>-sU</code> enables UDP scanning. Nmap often uses <code>--top-ports 20</code> (or a similar number) for UDP scans by default if no specific ports are given, as full UDP scans are very slow. Unicornscan is an alternative tool known for faster UDP scanning.',
        tips: ["UDP scan results can be unreliable; 'open|filtered' means Nmap couldn't determine if the port is open or firewalled.", "Version detection (<code>-sV</code>) is highly recommended for UDP scans to confirm services, as UDP is connectionless."]
      },
      {
        id: 'portscan-nse-scripts',
        title: 'Nmap Scripting Engine (NSE) for Enumeration & Vulnerability Identification',
        description: 'Use NSE scripts to perform more advanced enumeration and check for known vulnerabilities on discovered services.',
        commands: [
          { language: 'bash', code: (params: any) => `nmap ${params.targetHost || 'TARGET_IP_OR_HOSTNAME'} -p ${params.targetPort || '80,443'} -sV -sC -oA nmap_default_scripts_${params.targetHost || 'TARGET'}`, params: { targetHost: 'specific_target.example.com', targetPort: '80'}, showCopyButton: true },
          { language: 'bash', code: (params: any) => `nmap ${params.targetHost || 'TARGET_IP_OR_HOSTNAME'} -p ${params.targetPort || '21,22,80'} --script vuln -oA nmap_vuln_scan_${params.targetHost || 'TARGET'}`, params: { targetHost: 'specific_target.example.com', targetPort: '22'}, showCopyButton: true },
          { language: 'bash', code: `nmap --script-help "http*" # List NSE scripts related to http`, showCopyButton: false}
        ],
        explanation: '<code>-sC</code> runs default scripts (generally safe for discovery). <code>--script vuln</code> runs scripts categorized as vulnerability detection (can be more intrusive). You can also specify individual scripts or categories.',
        tips: ["Review what NSE scripts do before running them, especially categories like 'intrusive' or 'exploit'.", "Update NSE scripts regularly: <code>sudo nmap --script-updatedb</code>."]
      },
      {
        id: 'portscan-masscan',
        title: 'Alternative: Masscan for Very Fast Scans',
        description: 'Masscan is an extremely fast port scanner, useful for scanning large networks or the entire internet. It operates asynchronously and sends probes very quickly.',
        commands: [
          { language: 'bash', code: (params: any) => `masscan -p80,443,8080 ${params.ipRange || '192.168.0.0/16'} --rate=10000 -oL masscan_results.txt`, params: {ipRange: 'TARGET_IP_RANGE'}, showCopyButton: true },
        ],
        explanation: 'Masscan is designed for speed over a large number of hosts. It\'s excellent for quickly identifying hosts with specific open ports across a wide IP range. It does not perform service/version detection like Nmap by default.',
        tips: ["Masscan can be very disruptive if not used carefully. Ensure you have permission and understand its impact.", "Often used as an initial discovery step, with Nmap used for deeper analysis on hosts found by Masscan."]
      }
    ]
  },
  {
    id: 'subdomain-takeover',
    title: 'Subdomain Takeover Check',
    icon: 'fas fa-ghost',
    description: 'Identifies subdomains pointing to external services (e.g., S3, GitHub Pages, Heroku, Azure Traffic Manager) where the original account or resource has been removed or misconfigured. If vulnerable, an attacker can claim this resource and serve malicious content under the legitimate parent domain.',
    mockOutput: [
      { "subdomain": "test.example.com", "vulnerable_to": "S3 Bucket Takeover", "CNAME": "test.example.com.s3.amazonaws.com", "details": "Bucket not found or public write." },
      { "subdomain": "help.example.com", "vulnerable_to": "GitHub Pages Takeover", "CNAME": "username.github.io", "details": "Associated GitHub repository might be deleted or made private." },
      { "subdomain": "blog.example.com", "vulnerable_to": "Heroku App Takeover", "CNAME": "appname.herokuapp.com", "details": "Heroku app may no longer exist." }
    ],
    interactiveElement: {
        type: 'json-viewer',
        label: 'Mock Subdomain Takeover Output:'
    },
    explanation: 'Subdomain takeover vulnerabilities arise from dangling DNS CNAME records. When a subdomain CNAMEs to an external service, but the corresponding resource on that service is deprovisioned, an attacker might be able to register that resource name and hijack the subdomain.',
    tips: [
        "Regularly audit DNS records for CNAMEs pointing to third-party services.", 
        "Ensure proper deprovisioning processes: remove DNS records before or immediately after deleting resources on external services.",
        "Be cautious with wildcard CNAMEs that might inadvertently point to services that can be taken over."
    ],
    subSteps: [
        {
            id: 'subtakeover-tools',
            title: 'Automated Scanning for Takeovers',
            description: 'Utilize specialized tools to check a list of subdomains for common takeover signatures across various platforms.',
            commands: [
              { language: 'bash', code: 'subzy run --targets unique_resolved_hostnames.txt --vuln --hide_fails -o takeover_subzy_results.txt', showCopyButton: true },
              { language: 'bash', code: 'nuclei -l unique_resolved_hostnames.txt -t miscellaneous/dns/subdomain-takeover-detect.yaml -o takeover_nuclei_results.txt', showCopyButton: true },
            ],
            explanation: `<strong>Subzy:</strong> A popular tool that checks for known takeover patterns across many services.
                    <br />
                    <strong>Nuclei:</strong> Has templates specifically for detecting various subdomain takeover conditions. Ensure your Nuclei templates are up-to-date.`,
            tips: ["False positives can occur. Always manually verify potential takeovers.", "Some tools require API keys for certain checks (e.g., some checks in nuclei-templates)."]
        },
        {
            id: 'subtakeover-manual-verification',
            title: 'Manual Verification Techniques',
            description: 'Manually verify potential takeovers by inspecting CNAME records and attempting to register the target resource on the third-party service.',
            commands: [
                { language: 'bash', code: (params: any) => `dig CNAME ${params.subdomain || 'vulnerable.example.com'} +short # Check the CNAME record`, params: {subdomain: 'potential-takeover.example.com'}, showCopyButton: true},
                { language: 'text', code: `# Example: If CNAME points to non-existent S3 bucket "my-old-bucket.s3.amazonaws.com", try to create "my-old-bucket" in S3.`, showCopyButton: false}
            ],
            explanation: 'Check the CNAME record of the suspicious subdomain. If it points to a service like S3, GitHub Pages, Heroku, Azure, etc., visit the service provider\'s platform and see if you can claim the specific resource name (e.g., the S3 bucket name, the GitHub Pages repository name).',
            tips: ["Be extremely careful not to disrupt legitimate services during verification.", "Some services have specific error messages that indicate a resource is available for registration (e.g., \"NoSuchBucket\" for S3)."]
        }
    ]
  },
  {
    id: 'live-host-detection',
    title: 'Live Host Detection & HTTP Probe',
    icon: 'fas fa-heartbeat',
    description: 'Filter the list of subdomains to identify which ones are actually live and responding on HTTP/HTTPS, and gather initial information like titles, status codes, and technologies.',
    commands: [
      { language: 'bash', code: 'cat unique_resolved_hostnames.txt | httpx -silent -threads 100 -o live_http_hosts_temp.txt', showCopyButton: true },
      { language: 'bash', code: 'cat live_http_hosts_temp.txt | httpx -mc 200,301,302,307,401,403 -title -tech-detect -status-code -content-length -o httpx_full_info.txt', showCopyButton: true},
      { language: 'bash', code: 'cat httpx_full_info.txt | cut -d\' \' -f1 | sort -u > live_hosts_final.txt # Extract just live host URLs', showCopyButton: true },
      { language: 'bash', code: 'rm live_http_hosts_temp.txt', showCopyButton: false }
    ],
    visualizations: {
        type: 'bar-chart',
        data: { labels: ['Live (2xx)', 'Redirect (3xx)', 'Auth Req (401/403)', 'Other'], values: [75, 15, 8, 2] } 
    },
    explanation: '`httpx` is a fast and multi-purpose HTTP toolkit. First pass checks for any HTTP response. Second pass filters by interesting status codes (200s, 300s, 401, 403) and gathers more details. This helps prioritize targets.',
    tips: ["Use `-threads` to control concurrency. Higher threads are faster but can be more resource-intensive for you and the target.", "The `-mc` (match status codes) flag is very useful. Also consider `-fc` (filter status codes) to exclude noise.", "`-tech-detect` can reveal underlying technologies (CMS, frameworks, web servers)."]
  },
  {
    id: 'request-smuggling-check',
    title: 'HTTP Request Smuggling Check',
    icon: 'fas fa-truck-loading',
    description: 'Test for HTTP Request Smuggling vulnerabilities, which occur when frontend (e.g., load balancer, reverse proxy) and backend servers interpret ambiguous HTTP request boundaries differently. This can lead to cache poisoning, session hijacking, or bypassing security controls.',
    commands: [
      { language: 'bash', code: 'cat live_hosts_final.txt | smuggler -v -t 10 -x -o request_smuggling_results.txt', showCopyButton: true },
      { language: 'bash', code: `# Alternatively, use Burp Suite's HTTP Request Smuggler extension for more interactive testing.`, showCopyButton: false}
    ],
    interactiveElement: {
        type: 'info-tabs',
        label: 'Request Smuggling Techniques & Payloads',
        options: [
            {
                id: 'smuggling-cl-te',
                name: 'CL.TE (Content-Length then Transfer-Encoding)',
                content: `
                    <p>The frontend proxy uses the <code>Content-Length</code> header, while the backend server uses the <code>Transfer-Encoding: chunked</code> header. An attacker crafts a request that satisfies the frontend's Content-Length but includes a chunked body that the backend processes, leading to a "smuggled" prefix for the next request.</p>
                    <pre><code class="language-http">POST / HTTP/1.1\\nHost: vulnerable-site.com\\nContent-Length: 11\\nTransfer-Encoding: chunked\\n\\n0\\n\\nSMUGGLED</code></pre>
                `
            },
            {
                id: 'smuggling-te-cl',
                name: 'TE.CL (Transfer-Encoding then Content-Length)',
                content: `
                    <p>The frontend proxy uses <code>Transfer-Encoding: chunked</code>, while the backend uses <code>Content-Length</code>. The attacker sends a chunked request where the final chunk size misleads the frontend, causing the backend to process only part of the request based on a Content-Length header embedded by the proxy or the attacker, leaving the rest to be prepended to the next request.</p>
                    <pre><code class="language-http">POST / HTTP/1.1\\nHost: vulnerable-site.com\\nTransfer-Encoding: chunked\\nContent-Length: 4 # Ignored by frontend, used by backend\\n\\n5c # Chunk size for 'SMUGGLED_REQUEST_BODY' + CRLF\\nSMUGGLED_REQUEST_BODY\\n0\\n\\n</code></pre>
                `
            },
            {
                 id: 'smuggling-te-te',
                 name: 'TE.TE (Transfer-Encoding Obfuscation)',
                 content: "<p>Both servers nominally support chunked encoding, but one can be tricked into not processing it (e.g., by an obfuscated Transfer-Encoding header) while the other does, leading to desynchronization.</p>"
            },
            {
                 id: 'smuggling-impact',
                 name: 'Potential Impact',
                 content: "<p>Successful request smuggling can allow attackers to bypass frontend security controls (like WAFs or authentication checks), hijack other users' sessions, poison web caches, and access internal systems.</p>"
            }
        ]
    },
    explanation: 'Tools like "smuggler" or Burp Suite\'s extension automate testing for common request smuggling patterns (CL.TE, TE.CL, TE.TE). Detection involves sending ambiguous requests and observing if the server or subsequent requests behave unexpectedly. This vulnerability is highly dependent on the specific proxy and backend server configurations.',
    tips: ["Test with various HTTP methods (POST, GET, etc.).", "Carefully analyze server responses and any \"time-outs\" or unexpected content in subsequent requests.", "Request smuggling can be difficult to detect reliably and requires a good understanding of HTTP specifications and proxy behaviors."]
  },
  {
    id: 'directory-discovery',
    title: 'Directory & File Discovery (Content Discovery)',
    icon: 'fas fa-folder-open',
    description: 'Enumerate common and hidden directories, files, and API endpoints on web servers to find exposed resources, backup files, sensitive information, or administrative interfaces that are not meant to be public.',
    commands: [ 
      { 
        language: 'bash', 
        code: (params: any) => `dirsearch -l live_hosts_final.txt -o dirsearch_results.txt -i 200,301,302,401,403 -e ${params.extensions ? params.extensions.join(',') : 'php,html,txt,js,json,xml,bak,config,conf,old,zip,tar.gz,asp,aspx,jsp,do,action'} --exclude-status 400,404,500-599 -t 75 --plain-text-report=dirsearch_plain.txt`,
        params: { extensions: ['php', 'html', 'txt', 'js', 'json', 'xml', 'bak', 'config', 'conf', 'old', 'zip', 'tar.gz', 'asp', 'aspx', 'jsp', 'do', 'action', 'env', 'log'] },
        showCopyButton: true 
      },
      {
        language: 'bash',
        code: (params: any) => `ffuf -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt -u http://${params.targetHost || 'TARGET_HOST'}/FUZZ -H "Host: ${params.targetHost || 'TARGET_HOST'}" -mc 200,301,302,403 -o ffuf_dirs.json`, params: {targetHost: 'specific_target.example.com'}, showCopyButton: true
      },
      {
        language: 'bash',
        code: (params: any) => `gobuster dir -u http://${params.targetHost || 'TARGET_HOST'} -w /usr/share/seclists/Discovery/Web-Content/common.txt -x php,txt,html -k -o gobuster_common.txt`, params: {targetHost: 'specific_target.example.com'}, showCopyButton: true
      }
    ],
    interactiveElement: {
        type: 'tag-input',
        label: 'Additional File Extensions to Scan for (comma-separated):',
        initialValue: ['php', 'html', 'js', 'txt', 'bak', 'conf', 'config', 'json', 'xml', 'yml', 'yaml', 'env', 'log', 'aspx', 'asp', 'jsp', 'do', 'action'],
    },
    explanation: 'Tools like Dirsearch, ffuf, and Gobuster use wordlists (e.g., from SecLists) to guess directory and file names. Key configurations include specifying target extensions (<code>-e</code> for dirsearch, <code>-x</code> for gobuster), matching/excluding status codes (<code>-i</code>, <code>--exclude-status</code>), and adjusting thread counts (<code>-t</code>). Reviewing results often uncovers administration panels, backup files, exposed configuration files (e.g., <code>.env</code>, <code>web.config</code>), or sensitive logs.',
    tips: ["Use multiple diverse wordlists for better coverage (e.g., general web content, technology-specific paths, API routes).", "Pay attention to 401/403 responses; they indicate a resource exists but is protected, which might be bypassed later.", "Recursively scan interesting directories found (e.g., <code>dirsearch ... -R 2</code> for recursion depth 2).", "Customize User-Agent strings; some servers block default tool agents."]
  },
  {
    id: 'vulnerability-scanning-nuclei',
    title: 'Automated Vulnerability Scanning with Nuclei',
    icon: 'fas fa-biohazard',
    description: 'Leverage Nuclei and its extensive template library to automatically scan for known vulnerabilities, misconfigurations, exposed panels, CVEs, and other security issues across the discovered live hosts.',
    commands: [
      { language: 'bash', code: (params: any) => `nuclei -l live_hosts_final.txt -o nuclei_results.txt -t ~/nuclei-templates/${params.templateCategory || 'cves/'} -severity critical,high,medium,low -stats -timeout 5`, params: { templateCategory: 'cves' }, showCopyButton: true },
      { language: 'bash', code: `nuclei -update-templates # Keep templates updated`, showCopyButton: false },
      { language: 'bash', code: `nuclei -l live_hosts_final.txt -tags cve,osint,misc,default-logins -o nuclei_general_scan.txt`, showCopyButton: true }
    ],
    interactiveElement: {
        type: 'dropdown-selector',
        label: 'Select Nuclei Template Category/Path:',
        initialValue: 'cves', 
        options: [
            { value: 'cves/', label: 'CVEs (Specific Vulnerabilities)' },
            { value: 'technologies/', label: 'Technologies (e.g., WordPress, Jenkins)' },
            { value: 'misconfiguration/', label: 'Common Misconfigurations' },
            { value: 'default-logins/', label: 'Default Credentials' },
            { value: 'exposed-panels/', label: 'Exposed Admin Panels' },
            { value: 'file/', label: 'Sensitive File Exposure' },
            { value: 'takeovers/', label: 'Subdomain Takeovers (re-check)' },
            { value: 'workflows/', label: 'Complex Workflows (e.g., CVE + WAF bypass)'},
            { value: 'headless/', label: 'Headless Browser Checks'},
            { value: 'network/', label: 'Network Service Checks'}
        ]
    },
    explanation: 'Nuclei is a fast, template-based vulnerability scanner. Templates are YAML files defining requests and matchers. You can target specific template categories (<code>-t path/to/templates</code>), filter by severity (<code>-severity</code>), or use tags (<code>-tags</code>). Regularly updating templates (<code>nuclei -update-templates</code>) is crucial for new vulnerability checks.',
    tips: ["Run scans with specific, relevant tags for the technologies identified (e.g., <code>-tags wordpress,php</code>).", "Contribute to or develop custom Nuclei templates for specific application logic or newly discovered vulnerabilities in your target.", "Be aware of the <code>-rate-limit</code> (<code>-rl</code>) and <code>-bulk-size</code> (<code>-bs</code>) flags to control scan speed and avoid overwhelming targets or getting blocked."]
  },
  {
    id: 'url-gathering',
    title: 'URL Gathering (Historical & Active)',
    icon: 'fas fa-link',
    description: 'Collect all possible URLs and endpoints from various sources like Wayback Machine, web crawlers, and JavaScript files for further analysis.',
    commands: [
      { language: 'bash', code: 'cat live_hosts_final.txt | waybackurls > wayback_urls.txt', showCopyButton: true },
      { language: 'bash', code: 'katana -list live_hosts_final.txt -jc -kf -d 5 -c 30 -o katana_urls.txt # -jc for JS crawling, -kf for known files, -d depth, -c concurrency', showCopyButton: true },
      { language: 'bash', code: 'gospider -S live_hosts_final.txt -o gospider_output -c 20 -d 3 --js --sitemap --robots # Crawl with JS parsing', showCopyButton: true },
      { language: 'bash', code: 'cat wayback_urls.txt katana_urls.txt gospider_output/* | grep -E "\\.(js|php|html|aspx|asp|jsp|json|xml|txt|log|conf|config|env|bak|old|zip|tar\\.gz|do|action)(\\?|$)" | sort -u | anew > all_discovered_urls.txt', showCopyButton: true },
      { language: 'bash', code: 'rm wayback_urls.txt katana_urls.txt && rm -rf gospider_output # Cleanup', showCopyButton: false }
    ],
    interactiveElement: {
        type: 'progress-bar-simulation',
        label: 'URL Gathering Progress (Simulated):',
        options: [ 
            { name: 'Waybackurls', duration: 3000 },
            { name: 'Katana', duration: 5000 },
            { name: 'GoSpider', duration: 7000 },
            { name: 'Merging & Sorting', duration: 1000 }
        ]
    },
    explanation: 'Tools like waybackurls (Wayback Machine), Katana (active crawling), and Gospider help discover a wide range of URLs. Merging and sorting provides a unique list. The `grep` command filters for common interesting file extensions.',
    tips: ["Filter URLs further by keywords relevant to your target's functionality.", "Analyze JavaScript files extracted for API endpoints and hidden parameters.", "Use tools like `unfurl` to break down URLs into components for easier analysis and parameter mining."]
  },
  {
    id: 'analyze-js-php',
    title: 'Analyze JS & PHP Files for Endpoints/Secrets',
    icon: 'fab fa-js-square',
    description: 'Extract and analyze JavaScript and PHP files found in the previous step to discover API endpoints, hidden parameters, or potentially leaked secrets and sensitive information.',
    commands: [
      { language: 'bash', code: 'cat all_discovered_urls.txt | grep -E "\\.js(\\?|$)" | anew > js_files.txt', showCopyButton: true },
      { language: 'bash', code: 'cat all_discovered_urls.txt | grep -E "\\.php(\\?|$)" | anew > php_files.txt', showCopyButton: true },
      { language: 'bash', code: 'cat js_files.txt | xargs -I % sh -c \'curl -sk "%" | LinkFinder -i "%" -o cli\' > linkfinder_results.txt', showCopyButton: true },
      { language: 'bash', code: 'cat js_files.txt | xargs -I % sh -c \'trufflehog filesystem % --json > %.trufflehog.json\' # Scan each JS file URL for secrets', showCopyButton: true},
      { language: 'bash', code: '# Manually review interesting PHP files for includes, database queries, and logic flaws.', showCopyButton: false }
    ],
    interactiveElement: {
        type: 'file-list',
        label: 'Discovered Files (Mock - click to "preview"):',
        initialValue: [ 
            { name: 'app.bundle.min.js', path: 'https://example.com/static/js/app.bundle.min.js', type: 'js', content: '// Mock JS Content\\nconst API_ENDPOINT = "/api/v2/user_data";\\nfunction getUser(){ fetch(API_ENDPOINT); /* ... */ }\\n// Secret: "tmpDevApiKey=abcdef123456dontusethis"' },
            { name: 'old_config.php.bak', path: 'https://example.com/includes/old_config.php.bak', type: 'php', content: '<?php\\n// Mock PHP Content for backup file\\n$DB_USER = "root_backup";\\n$DB_PASS = "WeakPassword123!";\\n$OLD_API_KEY = "legacykey789";\\n?>' },
            { name: 'payment_processor.php', path: 'https://example.com/api/payment_processor.php', type: 'php', content: '<?php // Handles payment transactions, check for input validation and logic flaws... ?>'}
        ]
    },
    explanation: 'Filter for JS and PHP files. Use tools like LinkFinder to extract endpoints from JavaScript. TruffleHog scans for secrets. Manually review PHP files for includes, database interaction patterns, and business logic that might be vulnerable.',
    tips: ["Look for comments (e.g., TODO, FIXME, API_KEY), API endpoint patterns (e.g., /api/v[0-9]+/), and hardcoded credentials or tokens in JS files.", "For PHP, pay attention to `include/require` statements (potential LFI), database query construction (SQLi), and how user input is handled (XSS, Command Injection).", "Beautify minified JavaScript for easier reading (e.g., using online beautifiers or browser dev tools)."]
  },
  {
    id: 'parameter-discovery-arjun',
    title: 'Parameter Discovery with Arjun & ParamSpider',
    icon: 'fas fa-key',
    description: 'Discover hidden HTTP parameters for URLs (GET, POST, JSON), which can reveal unlinked functionality, input points for injection vulnerabilities (SQLi, XSS, SSRF), or mass assignment issues.',
    commands: [
      { language: 'bash', code: 'arjun -l all_discovered_urls.txt -oT arjun_results.txt -t 50 -c 10 --stable # Test GET, POST, JSON parameters', showCopyButton: true },
      { language: 'bash', code: (params: any) => `paramspider -d ${params.targetDomain || 'example.com'} -o paramspider_results.txt`, params: { targetDomain: 'example.com' }, showCopyButton: true },
    ],
     interactiveElement: {
        type: 'tabs',
        label: 'Parameter Discovery Techniques',
        options: [
            { 
                id: 'arjun-tech', 
                name: 'Arjun (Active Fuzzing)', 
                content: `
                    <p>Arjun actively fuzzes endpoints with a large list of common parameter names for GET, POST, and JSON requests. It observes changes in response length, status code, or content to identify valid parameters.</p>
                    <pre><code class="language-bash">arjun -u https://example.com/api/search -m GET -t 20</code></pre>
                    <p class="text-xs mt-1">This will test various GET parameters against the specific endpoint.</p>
                `
            },
            { 
                id: 'paramspider-tech', 
                name: 'ParamSpider (Passive Discovery)', 
                content: `
                    <p>ParamSpider crawls websites (including Wayback Machine archives) to find URL parameters used in JavaScript files, forms, and links. It's a passive approach.</p>
                    <pre><code class="language-bash">paramspider -d example.com --exclude css,jpg,png --level high</code></pre>
                    <p class="text-xs mt-1">This will passively discover parameters for example.com, excluding common static file extensions.</p>
                `
            }
        ]
    },
    explanation: 'Arjun actively fuzzes URLs with a comprehensive list of parameter names for various HTTP methods. ParamSpider passively crawls and analyzes web archives and JavaScript to find parameters. Discovered parameters are prime candidates for further vulnerability testing.',
    tips: ["Focus Arjun on dynamic endpoints (e.g., .php, .aspx, API routes) rather than static files.", "Use the <code>--stable</code> flag with Arjun for more reliable results, though it might be slower.", "Combine outputs and test each discovered parameter for common web vulnerabilities like XSS, SQLi, IDOR, etc."]
  },
  {
    id: 'sql-injection-sqlmap',
    title: 'SQL Injection Testing with sqlmap',
    icon: 'fas fa-database',
    description: 'Automate the detection and exploitation of SQL injection vulnerabilities using sqlmap on URLs with parameters discovered in previous steps. SQLmap can identify injectable parameters, fingerprint backend databases, and extract data.',
    commands: [ 
      { language: 'bash', code: (params: any) => `sqlmap -m arjun_results.txt --risk=${params.GET?.risk || 3} --level=${params.GET?.level || 5} --random-agent --banner --dbs --batch --output-dir=sqlmap_output/ --ignore-code=400,401,403,404`, params: { GET: { risk: 3, level: 5 } }, showCopyButton: true },
      { language: 'bash', code: (params: any) => `sqlmap -u "${params.POST?.targetUrl || 'https://example.com/vulnerable_endpoint_with_params'}" --data="${params.POST?.data || 'param1=test*&param2=another'}" --risk=${params.POST?.risk || 3} --level=${params.POST?.level || 5} --dbs --banner --batch --output-dir=sqlmap_output/`, params: { POST: { targetUrl: 'https://example.com/login', data: 'username=*&password=*', risk: 3, level: 5 } }, showCopyButton: true },
    ],
    interactiveElement: {
        type: 'parameter-form',
        label: 'SQLMap Command Generator',
        options: [
            { 
                id: 'sqlmap-get-url', 
                name: 'Single GET URL',
                fields: [
                    { id: 'targetUrl', label: 'Target URL (with parameters, mark injection point with *):', type: 'text', initialValue: 'https://example.com/product.php?id=1*' },
                    { id: 'risk', label: 'Risk (1-3):', type: 'number', initialValue: '3' },
                    { id: 'level', label: 'Level (1-5):', type: 'number', initialValue: '5' },
                ]
            },
            { 
                id: 'sqlmap-post-form', 
                name: 'POST Request (Form Data)',
                fields: [
                    { id: 'targetUrl', label: 'Target URL (endpoint):', type: 'text', initialValue: 'https://example.com/search.php' },
                    { id: 'data', label: 'POST Data (e.g., param1=value1*&param2=value2, mark injection points with *):', type: 'text', initialValue: 'query=*&category=all' },
                    { id: 'risk', label: 'Risk (1-3):', type: 'number', initialValue: '3' },
                    { id: 'level', label: 'Level (1-5):', type: 'number', initialValue: '5' },
                ]
            },
            {
                id: 'sqlmap-request-file',
                name: 'From Request File (e.g., Burp)',
                fields: [
                    { id: 'requestFile', label: 'Path to HTTP Request File:', type: 'text', initialValue: 'burp_request.req' },
                     { id: 'risk', label: 'Risk (1-3):', type: 'number', initialValue: '3' },
                    { id: 'level', label: 'Level (1-5):', type: 'number', initialValue: '5' },
                ]
            }
        ],
        initialValue: { currentMethod: 'GET' } 
    },
    explanation: 'Sqlmap is a powerful tool for SQL injection. Use <code>*</code> to mark potential injection points in URLs or POST data. Options like <code>--dbs</code>, <code>--tables</code>, <code>--columns</code>, <code>--dump</code> allow enumeration and exfiltration. <code>--batch</code> runs non-interactively. <code>-m <file></code> can test multiple URLs from a file (e.g., output from Arjun).',
    tips: ["Always use <code>--random-agent</code> to vary User-Agent. <code>--tamper</code> scripts can help bypass WAFs.", "Increase <code>--level</code> (1-5) and <code>--risk</code> (1-3) for more thorough tests, but be aware this increases request volume and intrusiveness.", "Use <code>--os-shell</code> or <code>--sql-shell</code> with extreme caution and only with explicit permission, as this attempts to gain OS or direct DB command execution.", "Ensure output directory (<code>--output-dir</code>) is specified to save session files and results systematically."]
  },
  {
    id: 'bonus-resolved-ips',
    title: 'Bonus: Resolved IPs Visualization & ASN Info',
    icon: 'fas fa-map-marked-alt',
    description: 'Resolve live hostnames to IP addresses, gather Autonomous System Number (ASN) information, and visualize their potential geographic locations. This can reveal hosting providers, CDN usage, and network ownership.',
    commands: [
      { language: 'bash', code: 'cat live_hosts_final.txt | dnsx -a -resp -silent -o resolved_ips_detailed.txt', showCopyButton: true },
      { language: 'bash', code: 'cat resolved_ips_detailed.txt | cut -d\' \' -f2 | tr -d \'[]\' | sort -u > unique_ips_for_geoip.txt', showCopyButton: true},
      { language: 'bash', code: '# Use unique_ips_for_geoip.txt with a GeoIP tool (e.g., geoiplookup or online services) or library (e.g. MaxMind GeoLite2 with Python) for visualization.', showCopyButton: false },
      { language: 'bash', code: 'cat unique_ips_for_geoip.txt | xargs -I{} sh -c \'whois -h whois.cymru.com " -v {}"\' > asn_info.txt # Get ASN info', showCopyButton: true}
    ],
    visualizations: {
        type: 'map',
    },
    explanation: 'Tools like `dnsx` or `massdns` quickly resolve hostnames to IPs. `dnsx -a -resp` provides the A record and IP. These IPs can then be fed into GeoIP databases (e.g., MaxMind GeoLite2) and plotted on a map. Querying WHOIS services like Cymru for ASN information (<code>whois -h whois.cymru.com " -v &lt;IP&gt;"</code>) reveals the network owner and prefix, which helps understand the infrastructure.',
    tips: ["GeoIP data is not always precise, especially for CDNs or Anycast IPs, but gives a general idea.", "ASN information can help identify if a target hosts its own infrastructure or uses specific cloud providers.", "Correlate this information with Nmap scans to understand network perimeters."]
  },
   {
    id: 'wordpress-enumeration',
    title: 'WordPress Enumeration & Scanning with WPScan',
    icon: 'fab fa-wordpress',
    description: 'If a WordPress site is identified (e.g., via httpx tech-detect or specific paths like /wp-login.php), use WPScan to enumerate users, plugins, themes, and check for known vulnerabilities. This is a critical step for WordPress targets.',
    commands: [
      { language: 'bash', code: (params: any) => `wpscan --url ${params.targetUrl || 'http://wordpress-target.com'} --enumerate u,ap,at,vt,vp,cb --api-token YOUR_WPSCAN_API_TOKEN -o wpscan_results.txt --random-user-agent --disable-tls-checks ${params.proxy ? '--proxy ' + params.proxy : ''}`, params: {targetUrl: 'http://wordpress.example.com', proxy: 'http://127.0.0.1:8080'}, showCopyButton: true },
      { language: 'bash', code: `# To find WordPress sites from your live hosts list:
cat httpx_full_info.txt | grep -i "WordPress" | awk '{print $1}' > wordpress_targets.txt
# Then run wpscan against wordpress_targets.txt (e.g., using a loop or xargs)
# for url in $(cat wordpress_targets.txt); do wpscan --url $url ... ; done`, showCopyButton: false}
    ],
    interactiveElement: {
        type: 'info-tabs',
        label: 'WPScan Enumeration Deep Dive',
        options: [
            { id: 'wpscan-enum-u', name: 'User Enumeration (u, eu)', content: '<code>-e u</code> enumerates usernames (e.g., via author archives from ID 1 to 10). <code>-e eu</code> is more aggressive. Be cautious with <code>eu</code> on sites with many users.'},
            { id: 'wpscan-enum-p', name: 'Plugin Enumeration (p, ap, vp)', content: '<code>-e p</code> enumerates plugins listed in HTML. <code>-e ap</code> (all plugins) performs extensive checks against a large list (can be slow). <code>-e vp</code> checks installed plugins for known vulnerabilities (requires API token).'},
            { id: 'wpscan-enum-t', name: 'Theme Enumeration (t, at, vt)', content: '<code>-e t</code> enumerates active theme. <code>-e at</code> enumerates all themes. <code>-e vt</code> checks active theme for known vulnerabilities (requires API token).'},
            { id: 'wpscan-enum-cb', name: 'Config Backups (cb)', content: 'Looks for publicly accessible config backup files like <code>wp-config.php.bak</code>.'},
            { id: 'wpscan-passwords', name: 'Password Brute-Forcing', content: '<code>wpscan --url &lt;url&gt; --passwords /path/to/wordlist.txt --usernames users.txt</code>. Use with extreme caution and explicit permission.'},
            { id: 'wpscan-api', name: 'API Token', content: 'A WPScan API token (free from wpvulndb.com) is needed for up-to-date vulnerability data lookups.'}
        ]
    },
    explanation: 'WPScan is a black box WordPress security scanner. Key enumeration flags: <code>-e u</code> (users), <code>ap</code> (all plugins), <code>at</code> (all themes), <code>vp</code> (vulnerable plugins), <code>vt</code> (vulnerable themes), <code>cb</code> (config backups). An API token is crucial for vulnerability data. Use <code>--random-user-agent</code> and consider <code>--disable-tls-checks</code> if issues with self-signed certs arise. Proxy support (<code>--proxy</code>) is useful for routing traffic through Burp.',
    tips: ["Always update WPScan and its database (<code>wpscan --update</code>).", "Focus on vulnerable plugins/themes identified, then search for public exploits.", "Brute-forcing logins should be a last resort and requires explicit permission due to its intrusiveness and potential for account lockouts.", "Check for exposed <code>xmlrpc.php</code> which can be abused for brute-force or DDoS amplification."]
  },
];
